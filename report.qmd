---
title: "Data Cleansing and Text Analysis Challenge"
author: "Hoang Son Pham"
format:
  html:
    code-fold: false
    toc: true
jupyter: python3
---

#Data Cleansing and Text Analysis Challenge

### Hoang Son Pham 

## Introduction

This project focuses on analyzing discussions about `ChatGPT` on the **Data Science Stack Exchange** platform. The analysis involves data cleansing, exploratory data analysis, sentiment analysis, and advanced insights extraction. By leveraging natural language processing (NLP) techniques, machine learning models, and geospatial visualization, the study aims to uncover patterns in user discussions, sentiment trends, and thematic categories. The project also emphasizes ethical considerations, ensuring user privacy and minimizing bias in the analysis. Through this comprehensive approach, the study provides valuable insights into how the data science community perceives and interacts with ChatGPT technology.



## 0. Import necessary libraries

```{python}
# General Packages for Data Manipulation and File Handling
import os
import re
import csv
import xml.etree.ElementTree as ET
import pandas as pd
import numpy as np
import requests
import json

# Text Processing and NLP Packages
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
from wordcloud import WordCloud
from transformers import pipeline
from scipy.special import softmax
from nltk.sentiment import SentimentIntensityAnalyzer
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
nltk.download('vader_lexicon')
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
# Machine Learning and Model Evaluation
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline


# Data Visualization
import seaborn as sns
import matplotlib.pyplot as plt
import folium
from folium.plugins import MarkerCluster
# Miscellaneous
from collections import Counter

import warnings
warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)

```

## 1. Create helper functions

```{python}
#Functions to convert xml file to csv file
def xml_to_csv(xml_file, csv_file):
    context = ET.iterparse(xml_file, events=("start", "end"))
    context = iter(context)
    _, root = next(context)
    rows = []
    for event, elem in context:
        if event == "end" and elem.tag == "row":
            rows.append(elem.attrib)
            elem.clear()
            root.clear()
    df = pd.DataFrame(rows)
    df.to_csv(csv_file, index=False)
```

```{python}
# Function to clean text by removing HTML tags and special characters
def clean_text(text):
    """Remove HTML tags and special characters from text using regex."""
    if pd.isna(text):
        return ''
    text = re.sub(r'http\S+|www\S+|https\S+', '', text) # Remove URLs
    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)  # Keep only letters, numbers and spaces
    return text.lower().strip()  # Convert to lowercase and remove leading/trailing spaces


```

```{python}
#Functions to find texts containing the keywords
def contains_topic(text, keywords):
    """
    Check if the text contains any of the specified keywords (case-insensitive).
    
    Parameters:
        text (str): The normalized text.
        keywords (list): List of keywords.
        
    Returns:
        bool: True if any keyword is found, False otherwise.
    """
    text_lower = text.lower()
    return any(keyword in text_lower for keyword in keywords)

```

```{python}
#Functions to remove stop words and lemmatize the text
def lemmatize_text(text):
    """
    Pipeline to normalize text by cleaning and optionally removing stopwords.
    
    Parameters:
        text (str): Raw text.
    
    Returns:
        str: Normalized text.
    """
    # Tokenize
    tokens = word_tokenize(text)
        
    # Remove stopwords and lemmatize
    processed_tokens = [
        WordNetLemmatizer().lemmatize(token) 
        for token in tokens 
        if token not in set(stopwords.words('english')) and len(token) > 2
    ]
        
    return ' '.join(processed_tokens)
```

```{python}
#Functions to count the number of words in a text block
def count_words(text):
    """Count the number of words in cleaned text."""
    if not text:
        return 0
    return len(re.findall(r'\b\w+\b', text))  # Match word boundaries
```

```{python}
#Function to check if the text has code
def count_code_blocks(text):
    """Count the number of <code> blocks in text using regex."""
    if pd.isna(text):
        return 0
    return len(re.findall(r'<code>.*?</code>', text, flags=re.DOTALL))
```

```{python}
#Initialize the sentiment analysis pipeline
sentiment_analyzer = SentimentIntensityAnalyzer()

#Function to calculate the polarity score of a text
def get_sentiment_score(text):
    """
    Calculate and return the sentiment score for the given text.
    The score represents the confidence (probability) for the predicted label.
    
    Parameters:
        text (str): The input text to analyze.
        
    Returns:
        float: The sentiment score.
    """
    result = sentiment_analyzer.polarity_scores(text)
    return result["compound"]
```

```{python}
#Function to classify the sentiment scores
def classify_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'
    
```

## 2. Load and explore the datasets

```{python}

# Set paths for the XML files and the new CSV output directory
xml_dir = "datascience.stackexchange.com"
csv_output_dir = "csv_output"

# Create the output directory if it doesn't exist
if not os.path.exists(csv_output_dir):
    os.makedirs(csv_output_dir)

# Loop through each file in the XML directory
for file in os.listdir(xml_dir):
    if file.lower().endswith(".xml"):
        xml_file_path = os.path.join(xml_dir, file)
        csv_file_name = f"{os.path.splitext(file)[0]}.csv"
        csv_file_path = os.path.join(csv_output_dir, csv_file_name)
        xml_to_csv(xml_file_path, csv_file_path)
```

```{python}
#Read the datasets
posts_df = pd.read_csv(os.path.join(csv_output_dir, 'Posts.csv'))
users_df = pd.read_csv(os.path.join(csv_output_dir, 'Users.csv'))
tags_df = pd.read_csv(os.path.join(csv_output_dir, 'Tags.csv'))
comments_df = pd.read_csv(os.path.join(csv_output_dir, 'Comments.csv'))
votes_df = pd.read_csv(os.path.join(csv_output_dir, 'Votes.csv'))
```

### Quick look at posts dataset

```{python}

posts_df.info()
posts_df.head()
```

### Quick look at users dataset

```{python}
users_df.info()
users_df.head()
```

### Quick look at tags dataset

```{python}
tags_df.info()
tags_df.head()
```

### Quick look at comments dataset

```{python}
comments_df.info()
comments_df.head()
```

## 3. Data Cleaning 

In this part, we will focus on cleaning the text data by removing the special characters, tags, HTML syntax and trailing spaces. These actions are executed using the helper functions that we created earlier. 

### Clean Posts dataset

```{python}
posts_df["CreationDate"] = pd.to_datetime(posts_df["CreationDate"] )
```

```{python}
drop_cols = ["PostTypeId", "LastActivityDate", "ClosedDate", "ContentLicense",
             "AcceptedAnswerId","LastEditorUserId","LastEditDate","ParentId", "OwnerDisplayName", "CommunityOwnedDate",
             "LastEditorDisplayName", "FavoriteCount"]
posts_df.drop(columns = drop_cols, inplace=True)
posts_df.info()

```

```{python}
posts_df['CleanBody'] = posts_df['Body'].apply(clean_text)
posts_df['CleanTitle'] = posts_df['Title'].apply(clean_text)
```

**As the Data Science stack exchange covers many topics, we will only focus on discussions about ChatGPT to investigate the people's opinions and concerns regarding this particular topic. Now we will search for posts containing the keywords: GPT, ChatGPT and OpenAI using regex and export them to a new dataframe**

### Filtering posts concerning ChatGPT

```{python}
#Keywords about Chatgpt
topic_keywords = ['gpt', 'chatgpt', 'openai']

#Search among the title and body texts to find the keywords and extract the related posts
gpt_post_df = posts_df[
    posts_df['CleanBody'].apply(lambda x:contains_topic(x, topic_keywords)) |
    posts_df['CleanTitle'].apply(lambda x:contains_topic(x, topic_keywords))
]
gpt_post_df.reset_index(drop=True, inplace=True)
print("Total posts related to GPT/ChatGPT:", len(gpt_post_df))
gpt_post_df.head()
```

```{python}
gpt_post_df.info()
```

```{python}
gpt_post_df["Body"] = gpt_post_df["Body"].fillna('')
gpt_post_df["Title"] = gpt_post_df["Title"].fillna('')
```

We have collected 390 posts related to ChatGPT. This is not a large number of posts considering the total the number of nearly 80k posts in the dataset. However, we can still reveal a lot of intriguing insights from this dataframe.

### Clean Comments dataset

Comments dataset is another source that requires deep investigation as we could reveal how people react and interact with certain type of contents

```{python}
comments_df.info()
```

We also clean the comment text to prepare for analysis

```{python}
comments_df["CleanText"] = comments_df["Text"].apply(clean_text)

```

We group the comments data by post ID and then join them together as one post can attract a lot of comments/interaction. This will make it easier for us to merge the datasets later on and analyze the relationship between the post and its specific comments. 

```{python}
comments_grouped = comments_df.groupby("PostId")["CleanText"].apply(' '.join).reset_index()
comments_grouped.columns = ["PostId", 'CleanComment']
```

```{python}
comments_grouped.info()
```

## 4. Exploratory Data Analysis

**In this part, we will perform some exploration steps on the posts to reveal some fundamental statistics about the dataset.**

```{python}
print(gpt_post_df.info())
print(gpt_post_df.iloc[:,1:].describe(include='number'))
```

### Distribution of posts over years

We draw a bar plot to identify the numbers of posts about ChatGPT over the years

```{python}
plt.figure(figsize=(10, 6))
sns.histplot(gpt_post_df['CreationDate'].dt.year,bins=10, color='skyblue', kde=True)
plt.title("Distribution of Creation Dates for GPT/ChatGPT Posts")
plt.xlabel("Creation Date")
plt.ylabel("Number of Posts")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

```

Looking at the bar chart, we can see that there are rarely any post about ChatGPT from 2015 to 2018. However the gradual rise was observed in the following year 2018 and 2019. The number of posts continued to surge and skyrocketed in 2023 with more than 180 posts. This paramount increase is explicable as 2023 saw the introduction of GPT-3 which shook the world significantly. The total number decreased sharply in 2024 which requires futher analysis.

### Distribution of total number of words in each post

We count the total number of words used in body text and title and create a histogram to plot the distribution

```{python}
#Count the total number of word using the count_words function
gpt_post_df['WordCount'] = gpt_post_df['CleanBody'].apply(count_words)

plt.figure(figsize=(10, 6))
sns.histplot(gpt_post_df['WordCount'], bins=30, kde=True, color='coral')
plt.title("Distribution of Word Counts for ChatGPT Posts")
plt.xlabel("Word Count")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()
```

Examining the distribution of word counts for GPT/ChatGPT posts reveals a clear tendency towards brevity. The most frequent post lengths cluster within the lower word count ranges, exhibiting a significant peak between approximately 50 and 100 words, with a substantial number also falling within the 100 to 200-word range. Beyond this point, the frequency of posts diminishes rapidly. The long tail extending towards higher word counts indicates that while the majority of discussions are concise, a small proportion of posts involve more extensive content. 

### Distribution of posts with code and without code

Count the number of code blocks used in each post and plot the distribution

```{python}
# Create a new column that counts the number of code blocks in each post using the original 'Body'
gpt_post_df['CodeCount'] = gpt_post_df['Body'].apply(count_code_blocks)

# Create a binary flag: True if the post has one or more code blocks, False otherwise
gpt_post_df['has_code'] = gpt_post_df['CodeCount'] > 0

# Count posts with and without code
code_counts = gpt_post_df['has_code'].value_counts().reset_index()
code_counts.columns = ['has_code', 'count']

# Relabel the flag for plotting purposes
code_counts['code_presence'] = code_counts['has_code'].map({True: 'Posts with Code', False: 'Posts without Code'})

# Plot the counts as a bar chart
plt.figure(figsize=(9, 6))
sns.barplot(y='code_presence', x='count', data=code_counts, palette='pastel')
plt.title("GPT/ChatGPT Posts: With vs Without Code")
plt.ylabel("Code Presence")
plt.tight_layout()
plt.show()
```

The number of posts that contain code blocks considerably outnumbers the plain posts. This revelation shows people's tendency of discussing technical implementation rather than other aspects of AI or ChatGPT in specific. This also presents the nature of forums in stack exchange which attract a lot or engineers and analysts. 

### Distribution of tags

We will explore what tags are most attached to users' posts

```{python}
# Function to extract tags from the Tag field
def extract_tags(tag_string):
    if pd.isna(tag_string):
        return []
    # Remove angle brackets and split by '><'
    tags = re.sub(r'[|]', ' ', tag_string).split()
    return [tag.strip() for tag in tags if tag.strip()]

# Extract tags from gpt_post_df
gpt_post_df['TagsList'] = gpt_post_df['Tags'].apply(extract_tags)

# Create a flattened list of all tags
all_tags = []
for tags in gpt_post_df['TagsList']:
    all_tags.extend(tags)

# Count tag frequencies
tag_counts = pd.Series(all_tags).value_counts()
top_tags = tag_counts.head(20)  # Top 20 tags
```

```{python}
# Create a horizontal bar chart with color gradient based on frequency
plt.figure(figsize=(12, 10))
ax = sns.barplot(
    y=top_tags.index,
    x=top_tags.values,
    palette=sns.color_palette("viridis", len(top_tags))
)

# Add count annotations to bars
for i, v in enumerate(top_tags.values):
    ax.text(v + 1, i, f"{v}", va='center')

# Set titles and labels
plt.title('Top 20 Tags in GPT/ChatGPT Posts', fontsize=16, fontweight='bold')
plt.xlabel('Frequency', fontsize=12)
plt.ylabel('Tag', fontsize=12)
plt.tight_layout()
plt.savefig('top_tags_gpt_posts.png', dpi=300, bbox_inches='tight')
plt.show()
```

Delving deeper into the chart, the prominence of "nlp" (Natural Language Processing) with 108 occurrences underscores its fundamental role in the context of GPT and ChatGPT, which are advanced NLP models. The tag "gpt" itself being the second most frequent (94) indicates a significant focus directly on the model architecture or its applications. Following these, we see "machine-learning" (59) and "reinforcement-learning" (44), highlighting the underlying methodologies used to train these powerful language models.

Interestingly, "transformer" (44) appears with the same frequency as "reinforcement-learning," pointing to the crucial transformer architecture that underpins GPT models. The presence of "deep-learning" (41) further reinforces the AI paradigm these models belong to. More application-oriented tags like "language-model" (34), "python" (30), and "openai-gym" (25) suggest discussions around the practical usage, coding environment, and related tools.

The drop in frequency after the top few tags is noticeable, indicating a long tail of more specific or less frequently discussed topics. The appearance of tags like "llm" (21), "finetuning" (17), "bert" (14), and "chatgpt" (13) shows engagement with specific model variants, training techniques, and the chatbot application itself. The presence of libraries like "tensorflow" (13) and "huggingface" (11) suggests discussions within the developer and practitioner communities. Finally, the lower frequency of more general AI terms like "ai" (10) and "word-embeddings" (10) might imply that discussions tend to be more focused on the specific models and techniques rather than broader AI concepts.

### Top tags over the years

We extract the top 5 common tags and plot their use over different years

```{python}
# Analyze how tags have evolved over time
gpt_post_df['Year'] = gpt_post_df['CreationDate'].dt.year

# Get top 5 tags for time series visualization
top5_tags = tag_counts.head(5).index.tolist()

# Create a dataframe for time series
tag_time_data = []
for year in range(2018, 2025):  # Adjust range based on your data
    year_posts = gpt_post_df[gpt_post_df['Year'] == year]
    year_tags = []
    for tags in year_posts['TagsList']:
        year_tags.extend(tags)
    
    if year_tags:  # Avoid empty years
        tag_counts_year = pd.Series(year_tags).value_counts()
        for tag in top5_tags:
            count = tag_counts_year.get(tag, 0)
            tag_time_data.append({'Year': year, 'Tag': tag, 'Count': count})

# Convert to DataFrame
tag_time_df = pd.DataFrame(tag_time_data)

# Create the time series plot
plt.figure(figsize=(14, 8))
ax = sns.lineplot(
    data=tag_time_df,
    x='Year',
    y='Count',
    hue='Tag',
    markers=True,
    dashes=False,
    linewidth=3,
    markersize=10
)

# Customize the plot
plt.title('Evolution of Top GPT/ChatGPT Tags Over Time', fontsize=16, fontweight='bold')
plt.xlabel('Year', fontsize=12)
plt.ylabel('Number of Posts', fontsize=12)
plt.legend(title='Tag', title_fontsize=12, fontsize=10, loc='upper left')
plt.grid(True, linestyle='--', alpha=0.7)
plt.xticks(range(2018, 2025))
plt.tight_layout()
plt.savefig('tag_evolution_gpt_posts.png', dpi=300, bbox_inches='tight')
plt.show()
```

Both "nlp" and "gpt" consistently show a higher number of associated posts compared to the other tags throughout the observed period, underscoring their central importance in discussions. Notably, "gpt" experiences a massive surge in 2023, coinciding with the widespread public release and adoption of advanced GPT models like ChatGPT. "nlp" also sees a significant peak in 2023, reflecting the broader interest in the underlying field.  
The tag "transformer" shows a steady increase in relevance, particularly becoming more prominent around 2022 and 2023. This aligns with the architectural innovation of transformer networks that power modern large language models, indicating increasing discussion about the underlying technology.  
While consistently present, the frequency of "machine-learning" and "reinforcement-learning" fluctuates more. "Machine-learning" sees a notable peak in 2023, likely driven by the overall surge in AI discussions. "Reinforcement-learning" shows a more modest and less pronounced trend, suggesting it might be a more specialized area of discussion within the broader GPT/ChatGPT context.


## 5. Word and Topic Analysis

Previously, we only performed statistical analysis on the post dataset without deeply investigating the actual textual content and semantics. In this section, we'll conduct a thorough exploration of the words used in ChatGPT discussions and attempt to identify the primary topics and themes emerging from these conversations. By analyzing word frequencies, distributions, and relationships, we'll uncover meaningful patterns that reveal how the data science community discusses, perceives, and utilizes ChatGPT technology. This deeper text analysis will complement our earlier statistical findings and provide richer insights into the discourse surrounding large language models.

### Lemmatize the title and body texts to prepare for analysis

In the cleaning step, we already removed all the redundant characters to better analyse the text data and their distribution. We will take a higher level step to lemmatize each word to extract meaningful and valueable words. \
**Lemmatization** is a crucial text normalization technique that reduces words to their base or dictionary form (known as a lemma), ensuring that different inflected forms of the same word are analyzed as a single item. Unlike simple stemming which often creates non-words by truncation, lemmatization preserves the semantic meaning by using vocabulary and morphological analysis to return proper word forms. In our analysis of ChatGPT-related discussions, we've implemented lemmatization to transform variants like "running," "runs," and "ran" to their common base form "run." This process significantly improves the quality of our word frequency analysis by consolidating related terms, preventing the dilution of important concepts across multiple word forms, and enabling more accurate identification of key topics. The lemmatization step represents a higher-level text processing approach that complements our earlier cleaning operations, allowing for more meaningful extraction of insights from the textual data.

The cleaned body text and the cleaned title are lemmatized and then concatenated to formulate a set of lemma words. We also removed all the Stop Words defined in the library. 

```{python}
gpt_post_df["PostText"] = gpt_post_df["CleanBody"].apply(lemmatize_text) + " " +  gpt_post_df["CleanTitle"].apply(lemmatize_text)
gpt_post_df["PostText"] 
```

For each post, there are no trivial words such as the, a, to, did,... but meaningful texts ready for further analysing. From now on, we can start revealing interesting insights from the dataset. 

### Extract most frequently used words and generate a word cloud

We create a dictionary of words in the posts and count the number of appearance. Then we create a wordcloud based on the frequency of each word.

```{python}
def get_top_words(text_series, n=50):
    """Extract top N frequent words from text series."""
    words = ' '.join(text_series.dropna()).split()
    word_counts = Counter(words)
    return pd.Series(word_counts).sort_values(ascending=False).head(n)

top_words_posts = get_top_words(gpt_post_df['PostText'], n=50)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words_posts)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of GPT/ChatGPT Posts')
plt.savefig('word_cloud_gpt.png')
plt.show()

```

We can easily observe that 'model', 'data', 'text', and 'use' are the most frequent words in the discussions about ChatGPT. These are common terms in AI or LLM field where we work with text data most of the time and try to build a model to unveil underlying relationships between words. Other noteworthy terms are 'language', 'gpt2' and 'openai' are all household names when we mention ChatGPT. 

### Plot the number of top used words

We draw a bar plot to visualize the appearances of top words in the discussions

```{python}
plt.figure(figsize=(13, 7))
sns.barplot(x=top_words_posts.values, y=top_words_posts.index, palette='viridis')
plt.title("Top Used Words in GPT/ChatGPT Posts")
plt.xlabel("Count")
plt.ylabel("Word")
plt.tight_layout()
plt.show()
```

'Model' is the top 1 word that has a striking number of nearly 1200 appearances. Far behind is 'data' with roughly 400 times and 'use' with 360 times. We also notice some interesting keywords in this list such as token(300 times), transformer(220 times) and training(200 times), all of which are fundamentals terminologies in LLM development. 

### Lemmatize the comment data to prepare for analysis

We lemmatize the comments as the way we did with the post data. 

```{python}
comments_grouped["LemmaComment"] = comments_grouped["CleanComment"].apply(lemmatize_text)
comments_grouped
```

We merge the post dataset and the comment dataset to extract relevant comments and perform further analysis on these two types. For the posts that do not have comments, we fill that with blank character. 

```{python}
merged_df = pd.merge(gpt_post_df, comments_grouped, how='left', left_on='Id', right_on='PostId')
merged_df['CleanComment'] = merged_df['CleanComment'].fillna('')
merged_df['LemmaComment'] = merged_df['LemmaComment'].fillna('')
                
# Combine post text and comments text
merged_df['CombinedText'] = merged_df['PostText'] + ' ' + merged_df['CleanComment']
merged_df.info()   
```

### Extract most frequently used words in the comments

We create a counter for each word and obtain the top 50 frequently used words. Then, we generate a wordcloud from the word list.

```{python}
top_words_comments = get_top_words(merged_df['LemmaComment'], n=50)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words_comments)
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud of GPT/ChatGPT Comments')
plt.show()
```

We still get 'model' as the most frequently used word in the comments. However, it is also observed that less technical terms appear in the comments when compared to the posts. 

### Plot the number of top words used in the comments

We plot a bar chart to see the number of each word's appearance

```{python}
plt.figure(figsize=(13, 7))
sns.barplot(x=top_words_comments.values, y=top_words_comments.index, palette='viridis')
plt.xlabel("Count")
plt.ylabel("Words")
plt.title("Top words count in the comments")
plt.tight_layout()
plt.show()
```

The chart gives that 'model' is a dominant term with nearly 130 times of appearing in the comments. That is followed by 'question' and 'answer' with approximately 90 times. There are also many natural language text such as 'would', 'can', 'will', 'the', 'is', 'like', 'dont', 'get', 'could' which are expected in any discussion. 

### Most common words in the posts vs common words in the comments

We identify words that appear in both top words lists and draw a grouped bar chart to visualize most common words in the posts and in the comments

```{python}
# Compute total counts for posts and comments
total_posts = top_words_posts.sum()
total_comments = top_words_comments.sum()

# Build a DataFrame that contains the percentages for each common word
data = []
for word in set(top_words_posts.index).intersection(set(top_words_comments.index)):
    data.append({
        'word': word,
        'Posts': top_words_posts[word] / total_posts * 100,
        'Comments': top_words_comments[word] / total_comments * 100
    })

df_percent = pd.DataFrame(data).sort_values(by='Posts', ascending=False)
df_percent.set_index('word', inplace=True)

# Plot the comparison as a grouped bar plot (percentages)
df_percent.plot(kind='bar', figsize=(14, 8))
plt.title("Comparison of Common Words Percentage\nin GPT/ChatGPT Posts vs Comments")
plt.xlabel("Word")
plt.ylabel("Percentage (%)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

This grouped bar chart compares the percentage of common words appearing in GPT/ChatGPT posts versus their comments. For most words, the percentage is higher in posts than in comments, indicated by the taller blue bars. However, notable exceptions include words like "answer," "also," and "get," which show a higher percentage in comments (taller orange bars). This suggests that while posts tend to utilize a broader vocabulary of these common terms, comments might disproportionately focus on providing answers, adding additional points ("also"), or employing more informal language ("get").

## 6. Sentiment Analysis

In this section, we analyze the emotional tone in discussions about ChatGPT. Using nltk sentiment analysis, we classify posts and comments as positive, neutral, or negative based on their compound sentiment scores. The analysis reveals distinct word usage patterns across sentiment categories through visualization techniques including sentiment-specific word clouds and comparative distribution charts. We examine both the frequency and context of key terms within each sentiment group, highlighting which words are uniquely associated with positive versus negative discussions. This sentiment breakdown provides valuable insights into how the data science community perceives ChatGPT technology, showing the balance of enthusiasm, neutrality, and criticism in technical discussions about large language models.



We take a look again at the merged dataframe

```{python}
merged_df.info()
merged_df.head()
```

### Count the total number of words of a post and its comment

```{python}
merged_df["TotalWordCount"] = (merged_df["CleanBody"] + " " + merged_df["CleanTitle"] + " " + merged_df["CleanComment"]).apply(count_words)

sentiment_df = merged_df.drop(columns=["Body", "Title", "Tags", "AnswerCount", "WordCount", "has_code", "PostId", "ViewCount"])
sentiment_df.info()
sentiment_df.head()
```

###  Calculate polarity score and Classify the sentiment

We will use the function `get_sentiment_score()` to calculate the polarity of each text and `classify_sentiment` to assign a label to each instance based on the score.

```{python}
#Calulate and classify sentiment score of the posts and their comments
sentiment_df["PostScore"] = sentiment_df["PostText"].apply(get_sentiment_score)
sentiment_df["CommentScore"] = sentiment_df["LemmaComment"].apply(get_sentiment_score)
sentiment_df["PostSentiment"] = sentiment_df["PostScore"].apply(classify_sentiment)
sentiment_df["CommentSentiment"] = sentiment_df["CommentScore"].apply(classify_sentiment)

sentiment_df
```

Now that we only focus on the sentiments of each discussion, we no longer need the text data in this section so we ill drop the redundant columns for better management.

```{python}
sentiment_df = sentiment_df.drop(columns=["CleanBody", "CleanTitle", "CleanComment","CombinedText"])
sentiment_df.info()
sentiment_df.head()

```

### Wordcloud for each sentiment category

We group the posts by sentiment, identify the top used words in each category and then generate wordclouds from them. 

```{python}
# Create separate dataframes for each sentiment category
positive_posts = sentiment_df[sentiment_df['PostSentiment'] == 'Positive']
neutral_posts = sentiment_df[sentiment_df['PostSentiment'] == 'Neutral']
negative_posts = sentiment_df[sentiment_df['PostSentiment'] == 'Negative']

# Prepare the word clouds by sentiment
plt.figure(figsize=(18, 5))

# Define custom color maps for each sentiment
positive_colormap = plt.cm.Greens
neutral_colormap = plt.cm.Blues
negative_colormap = plt.cm.Reds

# Generate top words for each sentiment
positive_words = get_top_words(positive_posts['PostText'], n=100)
neutral_words = get_top_words(neutral_posts['PostText'], n=100)
negative_words = get_top_words(negative_posts['PostText'], n=100)

# Create word clouds for each sentiment
plt.subplot(1, 3, 1)
if not positive_words.empty:
    positive_cloud = WordCloud(width=800, height=400, 
                             background_color='white',
                             colormap=positive_colormap,
                             max_words=100).generate_from_frequencies(positive_words)
    plt.imshow(positive_cloud, interpolation='bilinear')
    plt.title(f'Positive Sentiment Posts ({len(positive_posts)} posts)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No positive posts", fontsize=16, ha='center')
    plt.axis('off')

plt.subplot(1, 3, 2)
if not neutral_words.empty:
    neutral_cloud = WordCloud(width=800, height=400, 
                            background_color='white',
                            colormap=neutral_colormap,
                            max_words=100).generate_from_frequencies(neutral_words)
    plt.imshow(neutral_cloud, interpolation='bilinear')
    plt.title(f'Neutral Sentiment Posts ({len(neutral_posts)} posts)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No neutral posts", fontsize=16, ha='center')
    plt.axis('off')

plt.subplot(1, 3, 3)
if not negative_words.empty:
    negative_cloud = WordCloud(width=800, height=400, 
                             background_color='white',
                             colormap=negative_colormap,
                             max_words=100).generate_from_frequencies(negative_words)
    plt.imshow(negative_cloud, interpolation='bilinear')
    plt.title(f'Negative Sentiment Posts ({len(negative_posts)} posts)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No negative posts", fontsize=16, ha='center')
    plt.axis('off')

plt.tight_layout()
plt.savefig('sentiment_wordclouds.png', dpi=300, bbox_inches='tight')
plt.show()

```

- Positive Sentiment (402 posts): The most prominent word is "model" (in green), suggesting a focus on machine learning or AI models. Other frequent terms include "training," "data," "use," "like," and "language," indicating discussions around training AI models, datasets, and natural language processing. The large number of posts suggests strong interest or optimism in these topics.
- Neutral Sentiment (27 posts): The word "model" remains prominent (in blue), alongside "use," "data," and "training." Additional terms like "get," "open," and "system" appear, hinting at neutral discussions about model usage, data handling, and system implementation. The lower post count reflects less engagement compared to positive sentiment.
- Negative Sentiment (62 posts): Again, "model" stands out (in red), with "data," "use," and "training" also frequent. Terms like "error," "problem," "loss," and "need" suggest challenges or dissatisfaction, possibly related to model performance issues or data quality. The moderate post count indicates some frustration but less than the positive sentiment volume.

Overall, "model," "data," "use," and "training" are central across all sentiments, reflecting a common focus on AI development. Positive sentiment dominates, with neutral and negative sentiments showing more specific concerns or neutral observations.

### Distribution of post on different sentiment categories

We create a bar chart to visualize the number of post in each sentiment category

```{python}

# Print sentiment distribution
sentiment_counts = sentiment_df['PostSentiment'].value_counts()
print("Distribution of sentiments in posts:")
print(sentiment_counts)

# Create a bar chart of sentiment distribution
plt.figure(figsize=(7, 4))
sns.countplot(data=sentiment_df, x='PostSentiment', palette={'Positive': '#5cb85c', 'Neutral': '#5bc0de', 'Negative': '#d9534f'}, __annotations__=True)
plt.title('Distribution of Post Sentiments', fontsize=16)
plt.xlabel('Sentiment')
plt.ylabel('Number of Posts')
plt.tight_layout()
plt.show()
```

### Words Sentiment Proportion

We concatenate the top words in each sentiment category and then count the appearance of each word in all categories. We use a stacked bar chart to demonstrate the percentage of each word's presence in every sentiment category. 

```{python}


# Get top 20 words for each sentiment category
top_pos_words = positive_words.head(20)
top_neu_words = neutral_words.head(20)
top_neg_words = negative_words.head(20)

# Combine all unique words from the top words in each category
all_top_words = list(set(top_pos_words.index) | set(top_neu_words.index) | set(top_neg_words.index))

# Create a dataframe with word counts by sentiment
word_sentiment_df = pd.DataFrame(index=all_top_words, columns=['Positive', 'Neutral', 'Negative'])
word_sentiment_df = word_sentiment_df.fillna(0)

# Fill in the values
for word in all_top_words:
    if word in top_pos_words:
        word_sentiment_df.loc[word, 'Positive'] = top_pos_words[word]
    if word in top_neu_words:
        word_sentiment_df.loc[word, 'Neutral'] = top_neu_words[word]
    if word in top_neg_words:
        word_sentiment_df.loc[word, 'Negative'] = top_neg_words[word]

# Calculate total mentions of each word
word_sentiment_df['Total'] = word_sentiment_df.sum(axis=1)

# Sort by total mentions
word_sentiment_df = word_sentiment_df.sort_values('Total', ascending=False).head(25)

# Calculate percentages for each sentiment
for col in ['Positive', 'Neutral', 'Negative']:
    word_sentiment_df[f'{col}_pct'] = word_sentiment_df[col] / word_sentiment_df['Total'] * 100

# Create a stacked percentage bar chart
plt.figure(figsize=(12, 8))
words = word_sentiment_df.index
pos_pct = word_sentiment_df['Positive_pct']
neu_pct = word_sentiment_df['Neutral_pct']
neg_pct = word_sentiment_df['Negative_pct']

# Create the stacked bars
plt.barh(words, pos_pct, color='#5cb85c', alpha=0.7, label='Positive')
plt.barh(words, neu_pct, left=pos_pct, color='#5bc0de', alpha=0.7, label='Neutral')
plt.barh(words, neg_pct, left=pos_pct+neu_pct, color='#d9534f', alpha=0.7, label='Negative')

plt.xlabel('Percentage (%)')
plt.ylabel('Word')
plt.title('Distribution of Top Words Across Sentiment Categories', fontsize=16)
plt.legend(loc='upper right')
plt.tight_layout()
plt.savefig('sentiment_words_distribution.png', dpi=300, bbox_inches='tight')
plt.show()
```

We can see from the chart that most top words incur positive reactions, some of which dominate words like 'input', 'word', 'dataset' and 'training'. Looking ar the top of the chart, we still observe words fully assigned with negativity. 'Code', 'tokenizer', 'class' are such striking examples,

### Distribution of comments based on sentiments

We identify how many comments there are in each sentiment category and generate word cloud

```{python}
# Create separate dataframes for each sentiment category
positive_posts = sentiment_df[sentiment_df['CommentSentiment'] == 'Positive']
neutral_posts = sentiment_df[sentiment_df['CommentSentiment'] == 'Neutral']
negative_posts = sentiment_df[sentiment_df['CommentSentiment'] == 'Negative']

# Prepare the word clouds by sentiment
plt.figure(figsize=(18, 5))

# Define custom color maps for each sentiment
positive_colormap = plt.cm.Greens
neutral_colormap = plt.cm.Blues
negative_colormap = plt.cm.Reds

# Generate top words for each sentiment
positive_words = get_top_words(positive_posts['LemmaComment'], n=100)
neutral_words = get_top_words(neutral_posts['LemmaComment'], n=100)
negative_words = get_top_words(negative_posts['LemmaComment'], n=100)

# Create word clouds for each sentiment
plt.subplot(1, 3, 1)
if not positive_words.empty:
    positive_cloud = WordCloud(width=800, height=400, 
                             background_color='white',
                             colormap=positive_colormap,
                             max_words=100).generate_from_frequencies(positive_words)
    plt.imshow(positive_cloud, interpolation='bilinear')
    plt.title(f'Positive Sentiment Comments ({len(positive_posts)} comments)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No positive comments", fontsize=16, ha='center')
    plt.axis('off')

plt.subplot(1, 3, 2)
if not neutral_words.empty:
    neutral_cloud = WordCloud(width=800, height=400, 
                            background_color='white',
                            colormap=neutral_colormap,
                            max_words=100).generate_from_frequencies(neutral_words)
    plt.imshow(neutral_cloud, interpolation='bilinear')
    plt.title(f'Neutral Sentiment Comments ({len(neutral_posts)} comments)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No neutral comments", fontsize=16, ha='center')
    plt.axis('off')

plt.subplot(1, 3, 3)
if not negative_words.empty:
    negative_cloud = WordCloud(width=800, height=400, 
                             background_color='white',
                             colormap=negative_colormap,
                             max_words=100).generate_from_frequencies(negative_words)
    plt.imshow(negative_cloud, interpolation='bilinear')
    plt.title(f'Negative Sentiment Comments ({len(negative_posts)} comments)', fontsize=16)
    plt.axis('off')
else:
    plt.text(0.5, 0.5, "No negative comments", fontsize=16, ha='center')
    plt.axis('off')

plt.tight_layout()
plt.show()

```

- Positive Sentiment (145 comments): The most prominent word is "answer" (in green), suggesting satisfaction with responses or solutions. Other frequent terms include "model," "question," "use," "data," "problem," "training," "like," and "token," indicating discussions around AI models, problem-solving, and data usage. The moderate comment count reflects a positive but not dominant sentiment.
- Neutral Sentiment (326 comments): The word "model" stands out (in blue), alongside "use," "text," "see," "think," "get," "question," and "answer." Terms like "maybe," "could," "seems," and "please" suggest neutral inquiries or considerations about model usage and text processing. The high comment count indicates significant neutral engagement.
- Negative Sentiment (20 comments): The word "problem" is prominent (in red), with "error," "failed," "sorry," and "don't" also notable, pointing to issues or dissatisfaction, possibly with model performance or results. Other terms like "understand" and "need" suggest frustration or requests for clarification. The low comment count indicates limited negative feedback.

Overall, "model," "use," "answer," and "question" are central across sentiments, with neutral comments dominating, positive comments showing approval, and negative comments highlighting challenges.

```{python}
# Print sentiment distribution
sentiment_counts = sentiment_df['CommentSentiment'].value_counts()
print("Distribution of sentiments in comments:")
print(sentiment_counts)

# Create a bar chart of sentiment distribution
plt.figure(figsize=(7, 4))
sns.countplot(data=sentiment_df, x='CommentSentiment', palette={'Positive': '#5cb85c', 'Neutral': '#5bc0de', 'Negative': '#d9534f'})
plt.title('Distribution of Comment Sentiments', fontsize=16)
plt.xlabel('Sentiment')
plt.ylabel('Number of Comments')
plt.tight_layout()
plt.show()

```

### Words Sentiment Proportion in Comments

```{python}


# Get top 20 words for each sentiment category
top_pos_words = positive_words.head(20)
top_neu_words = neutral_words.head(20)
top_neg_words = negative_words.head(20)

# Combine all unique words from the top words in each category
all_top_words = list(set(top_pos_words.index) | set(top_neu_words.index) | set(top_neg_words.index))

# Create a dataframe with word counts by sentiment
word_sentiment_df = pd.DataFrame(index=all_top_words, columns=['Positive', 'Neutral', 'Negative'])
word_sentiment_df = word_sentiment_df.fillna(0)

# Fill in the values
for word in all_top_words:
    if word in top_pos_words:
        word_sentiment_df.loc[word, 'Positive'] = top_pos_words[word]
    if word in top_neu_words:
        word_sentiment_df.loc[word, 'Neutral'] = top_neu_words[word]
    if word in top_neg_words:
        word_sentiment_df.loc[word, 'Negative'] = top_neg_words[word]

# Calculate total mentions of each word
word_sentiment_df['Total'] = word_sentiment_df.sum(axis=1)

# Sort by total mentions
word_sentiment_df = word_sentiment_df.sort_values('Total', ascending=False).head(25)

# Calculate percentages for each sentiment
for col in ['Positive', 'Neutral', 'Negative']:
    word_sentiment_df[f'{col}_pct'] = word_sentiment_df[col] / word_sentiment_df['Total'] * 100

# Create a stacked percentage bar chart
plt.figure(figsize=(12, 8))
words = word_sentiment_df.index
pos_pct = word_sentiment_df['Positive_pct']
neu_pct = word_sentiment_df['Neutral_pct']
neg_pct = word_sentiment_df['Negative_pct']

# Create the stacked bars
plt.barh(words, pos_pct, color='#5cb85c', alpha=0.7, label='Positive')
plt.barh(words, neu_pct, left=pos_pct, color='#5bc0de', alpha=0.7, label='Neutral')
plt.barh(words, neg_pct, left=pos_pct+neu_pct, color='#d9534f', alpha=0.7, label='Negative')

plt.xlabel('Percentage (%)')
plt.ylabel('Word')
plt.title('Distribution of Top Words Across Sentiment Categories', fontsize=16)
plt.legend(loc='upper right')
plt.tight_layout()
plt.show()
```

The pattern does not change much for the comments data. Most top words have positive sentiments and few of them have mixed reactions. The observation for negative words are even more striking where the top 5 words 100% are mentioned in sentences with negative sentiments. 

### Comparison of number of posts and comments in each sentiment category

```{python}
# Create a dataframe to hold the sentiment distribution for both posts and comments
post_sentiment_counts = sentiment_df['PostSentiment'].value_counts().reset_index()
post_sentiment_counts.columns = ['Sentiment', 'Count']
post_sentiment_counts['Source'] = 'Posts'

comment_sentiment_counts = sentiment_df['CommentSentiment'].value_counts().reset_index()
comment_sentiment_counts.columns = ['Sentiment', 'Count']
comment_sentiment_counts['Source'] = 'Comments'

# Combine the dataframes
sentiment_comparison_df = pd.concat([post_sentiment_counts, comment_sentiment_counts])

# Define the color palette for sentiments
sentiment_colors = {'Positive': '#5cb85c', 'Neutral': '#5bc0de', 'Negative': '#d9534f'}

# Create the grouped bar chart
plt.figure(figsize=(10, 6))
ax = sns.barplot(
    x='Sentiment', 
    y='Count', 
    hue='Source', 
    data=sentiment_comparison_df,
    palette='pastel'
)

# Add value labels on top of each bar
for container in ax.containers:
    ax.bar_label(container, fmt='%d', padding=3)

# Customize the chart
plt.title('Distribution of Sentiments: Posts vs Comments', fontsize=16)
plt.xlabel('Sentiment Category', fontsize=12)
plt.ylabel('Count', fontsize=12)
plt.legend(title='Source')
plt.grid(axis='y', alpha=0.3, linestyle='--')
plt.tight_layout()

# Show the plot
plt.savefig('sentiment_comparison.png', dpi=300, bbox_inches='tight')
plt.show()
```

Posts show a significantly higher number of positive sentiment (402) compared to negative (62) and neutral (27) sentiments. This suggests that the initial content being shared tends to lean towards a positive outlook.
In contrast, comments exhibit the highest count in the neutral category (326), followed by positive (145) and then negative (20). This could indicate that discussions in the comment sections are often more objective, factual, or less emotionally charged compared to the initial posts.

### Grouped bar charts to display common words in posts and comments based on sentiment category

We extract top words in each sentiment category for post and comments data separately. Then we filter simmilar words in posts and comments from the list and then plot them onto a bar chart

```{python}
# Define sentiments to analyze
sentiments = ['Positive', 'Neutral', 'Negative']

# Create subplots for each sentiment category
fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for i, sentiment in enumerate(sentiments):
    # Filter the dataframe for posts and comments with the current sentiment
    posts_subset = sentiment_df[sentiment_df['PostSentiment'] == sentiment]
    comments_subset = sentiment_df[sentiment_df['CommentSentiment'] == sentiment]
    
    # Extract the top words (you can adjust the number "n" as needed)
    post_words = get_top_words(posts_subset['PostText'], n=30)
    comment_words = get_top_words(comments_subset['LemmaComment'], n=30)
    
    # Find common words between posts and comments for this sentiment
    common_words = set(post_words.index).intersection(set(comment_words.index))
    
    if not common_words:
        axes[i].text(0.5, 0.5, 'No common words found', horizontalalignment='center', verticalalignment='center')
        axes[i].set_title(f'{sentiment} Sentiment')
        axes[i].axis('off')
        continue

    # Build a DataFrame with frequencies from posts and comments for these common words
    common_freq = pd.DataFrame({
        'Posts': post_words.loc[list(common_words)],
        'Comments': comment_words.loc[list(common_words)]
    }).fillna(0)
    
    # Sort by the frequency in posts for a better horizontal bar chart presentation
    common_freq = common_freq.sort_values('Posts', ascending=True)
    
    # Plot a side-by-side horizontal bar chart for the current sentiment
    common_freq.plot(kind='barh', ax=axes[i])
    axes[i].set_title(f'{sentiment} Sentiment - Common Words')
    axes[i].set_xlabel('Frequency')
    axes[i].set_ylabel('Word')

plt.tight_layout()
plt.show()
```

**Positive Sentiment**: The chart for positive sentiment is dominated by the word "model" in posts, appearing far more frequently than any other word. Other common positive words in posts include "data," "like," and "use." Comments associated with positive sentiment show a much lower overall word frequency, with "model" and "data" still being relatively common.

**Neutral Sentiment**: For neutral sentiment, "model" again appears frequently in both posts and comments, with posts showing a higher count. Other notable neutral words in posts include "use," "text," and "openai." Comments exhibit a lower frequency for these words, with "answer" and "embedding" being relatively more prominent compared to the positive sentiment comments.

**Negative Sentiment**: The negative sentiment chart reveals "model" as the most frequent word in posts, although its dominance is less pronounced than in the positive sentiment category. Words like "action," "get," and "one" also appear with some frequency in negative posts. Similar to the other sentiment categories, comments associated with negative sentiment have a lower overall word frequency, with "model" and "get" being relatively more common.

Overall, "Model" appears to be a highly frequent term across all sentiment categories in posts, suggesting it's a central topic of discussion regardless of sentiment. Comments generally exhibit lower word frequencies compared to posts across all sentiment types. There are some variations in the most frequent words within comments for different sentiments, hinting at specific linguistic patterns associated with expressing positive, neutral, or negative opinions.

## 7. Correlation Analysis

In this section, we explore the statistical relationships between different features in our ChatGPT discussions dataset. By examining correlation patterns, we can uncover how factors like sentiment scores, code content, post length, and engagement metrics interact with each other. We'll employ robust scaling techniques to address the varying scales and distributions of our features, followed by regression analysis to identify which factors most strongly predict sentiment outcomes. The visualization of these relationships through correlation heatmaps and feature distribution plots will help us better understand the underlying patterns in how data science professionals discuss and engage with ChatGPT technology. This correlation analysis complements our earlier text and sentiment exploration by quantifying the connections between various aspects of the discourse, providing a more comprehensive understanding of the factors that shape perceptions and discussions around large language models.



Take a look again at the sentiment dataframe

```{python}
sentiment_df.info()
```

### Classify the sentiment of the complete posts

Concatenate the posts and their commments and calculate the polarity score to identify the sentiment category

```{python}
sentiment_df["CombinedSentimentScore"] = (sentiment_df["PostText"] + ' ' + sentiment_df["LemmaComment"]).apply(get_sentiment_score)

sentiment_df['CombinedSentiment'] = sentiment_df['CombinedSentimentScore'].apply(classify_sentiment)

```

### Drop columns to prepare for analysis

```{python}
sentiment_df = sentiment_df.drop(columns=["Id","PostText", "LemmaComment", "PostSentiment", "CommentSentiment", "CreationDate", "CombinedSentiment"])
sentiment_df
```

### Basic statistics

```{python}
sentiment_df.describe()
```

### Pearson's correlation of the features

```{python}
correlation = sentiment_df.drop(columns="TagsList").corr()
plt.figure(figsize=(13,9))
sns.heatmap(correlation,annot=correlation, cmap="viridis")
plt.title("Correlation Heatmap of the features")
```

Key Observations:
- PostScore and CombinedSentimentScore (0.92): There's a very strong positive correlation between PostScore and CombinedSentimentScore, suggesting that these two features are highly related or that PostScore is a major component of CombinedSentimentScore.
- TotalWordCount with CommentCount (0.37) and CodeCount (0.43): These moderate positive correlations indicate that posts with more words tend to have more comments or code.
- CommentCount with TotalWordCount (0.37): Similarly, higher comment counts are moderately associated with a greater total word count.


### Distribution of numeric features

```{python}
fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize=(18, 10))
axes = axes.flatten()
for i, col in enumerate(sentiment_df.drop(columns=["TagsList", "OwnerUserId"]).columns):
    sns.histplot(
            data=sentiment_df, 
            x=col, 
            kde=True,
            ax=axes[i],
            alpha=0.7,
            edgecolor='white',
            linewidth=0.5
        )
        
        # Add title and labels
    axes[i].set_title(f'Distribution of {col}', fontweight='bold')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Frequency')
    # Add grid for better readability
    axes[i].grid(axis='y', alpha=0.3, linestyle='--')
        
    # Calculate and display mean and median
    mean_val = sentiment_df[col].mean()
    median_val = sentiment_df[col].median()
        
    # Draw vertical lines for mean and median
    axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, linewidth=1.5)
    axes[i].axvline(median_val, color='green', linestyle='-.', alpha=0.8, linewidth=1.5)
        
    # Add text annotations for mean and median
    axes[i].text(
            x=mean_val, 
            y=axes[i].get_ylim()[1]*0.95, 
            s=f'Mean: {mean_val:.2f}', 
            color='red',
            fontweight='bold',
            horizontalalignment='center',
            bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3')
        )
    axes[i].text(
            x=median_val, 
            y=axes[i].get_ylim()[1]*0.85, 
            s=f'Median: {median_val:.2f}', 
            color='green',
            fontweight='bold',
            horizontalalignment='center',
            bbox=dict(facecolor='white', alpha=0.8, boxstyle='round,pad=0.3')
        )
    #Clear the unsued plot
    if i == 8: 
        axes[i].cla()
        axes[i].axis('off')
plt.tight_layout()
plt.suptitle('Distribution of Features in GPT/ChatGPT Sentiment Analysis', fontsize=16, y=1.02)
plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')
plt.show()
    
```

Many features, such as 'Score', 'CommentCount', 'CodeCount', 'TotalWordCount', 'CommentScore', and 'CombinedSentimentScore', exhibit a strong right-skew, with a high frequency of observations concentrated at the lower end of their respective ranges and a long tail extending towards higher values. This skewness is further emphasized by the often significant difference between the mean (red dashed line) and the median (green dashed line), where the mean is pulled to the right by the tail of the distribution. Conversely, the 'Distribution of Year' shows a more uniform or bimodal distribution. Given the prevalence of skewed distributions and the presence of potential outliers in features like 'CommentCount' or 'TotalWordCount', the use of a robust scaler would be highly advantageous. A robust scaler scales features using statistics that are more robust to outliers (like the median and interquartile range) instead of the mean and standard deviation, which are sensitive to extreme values. This approach would help prevent outliers from disproportionately influencing the scaling process, leading to a more normalized and stable feature representation for machine learning models.

**As this is a prediction task with very small number of instances, we will perform a simple linear regression analysis on the dataset to predict the total sentiment score**

### Split the variables into features and target

```{python}
# Select features and target
X = sentiment_df[['CodeCount', 'Score', 'TotalWordCount', 'CommentCount', 'PostScore', 'CommentScore']]
y = sentiment_df['CombinedSentimentScore']  # Using the continuous sentiment score

```

### Train-Test split

```{python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a pipeline with scaling and linear regression
scaler = RobustScaler()
X_train = scaler.fit_transform(X_train)
# Fit the model
linear_model=LinearRegression()
linear_model.fit(X_train, y_train)

# Transform the test data
X_test = scaler.transform(X_test)
# Make predictions
y_pred = linear_model.predict(X_test)

```

### Evaluate the models 

```{python}

# 8. Evaluate the model
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

# 9. Print model performance metrics
print(f"Model Performance with Scaled Features:")
print(f"Mean Squared Error: {mse:.4f}")
print(f"Root Mean Squared Error: {rmse:.4f}")
print(f"R-squared: {r2:.4f}")

# 10. Get feature coefficients (after scaling)
coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': linear_model.coef_
}).sort_values('Coefficient', ascending=False)

# 11. Visualize feature coefficients
plt.figure(figsize=(12, 8))
sns.barplot(x='Coefficient', y='Feature', data=coefficients, palette='viridis')
plt.title('Linear Regression Coefficients for Sentiment Prediction (Scaled Features)', fontsize=16)
plt.xlabel('Standardized Coefficient Magnitude')
plt.axvline(x=0, color='red', linestyle='--')
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.savefig('scaled_sentiment_regression_coefficients.png', dpi=300, bbox_inches='tight')
plt.show()
```

The model's performance metrics indicate a strong fit:
- Mean Squared Error (MSE): 0.0214, which is low, indicating small average squared differences between predicted and actual values.
- Root Mean Squared Error (RMSE): 0.1463, showing the average prediction error in the same units as the target variable.
- R-squared (R): 0.9227, meaning 92.27% of the variance in the target variable is explained by the model.

This suggests the model is performing well with scaled features. If further improvement is needed, consider exploring feature engineering, hyperparameter tuning, or more complex models.

### Plot the predicted sentiment score against the target

```{python}

# Visualize actual vs predicted values
plt.figure(figsize=(10, 8))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([-1, 1], [-1, 1], 'r--')  # Perfect prediction line
plt.xlabel('Actual Sentiment Score')
plt.ylabel('Predicted Sentiment Score')
plt.title('Actual vs. Predicted Sentiment Scores (Scaled Features)', fontsize=16)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('scaled_sentiment_actual_vs_predicted.png', dpi=300, bbox_inches='tight')
plt.show()

```

This scatter plot effectively visualizes the performance of a sentiment prediction model by comparing actual scores on the x-axis against predicted scores on the y-axis. The dashed red line represents perfect prediction, and the model generally exhibits a strong positive correlation, with data points clustering well around this line, particularly for actual sentiment scores ranging from neutral to highly positive. This indicates high predictive accuracy in these ranges. While the overall fit is good, there is a noticeable increase in scatter for negative sentiment scores (below approximately -0.25), suggesting slightly less precision in predicting more negative sentiments compared to positive ones. The density of points appears higher at the more positive end of the spectrum, and the use of "Scaled Features" implies standard data preprocessing for improved model performance. Overall, the model demonstrates robust predictive capabilities, though there's a minor area for potential refinement in the prediction of negative sentiments.

## 8. Location Analysis

In this section, we explore the geographical distribution of discussions about ChatGPT by analyzing user-provided location data. By mapping the sentiment and engagement metrics of posts across different regions, we aim to uncover patterns in how ChatGPT is perceived and discussed globally. Using geocoding techniques, we convert location data into coordinates and visualize the results on an interactive map. This analysis provides valuable insights into regional trends, highlighting areas with high engagement and varying sentiment toward ChatGPT.



### Merge the users dataset with the gpt posts 

We will extract the users that created posts on ChatGPT and recalculate the sentiment scores

```{python}
# Extract location data from users and merge with sentiment data
user_locations = users_df[['Id', 'Location']].dropna(subset=['Location'])
user_locations = user_locations.rename(columns={'Id': 'OwnerUserId'})

# Merge user locations with posts
location_df = pd.merge(
    left=gpt_post_df[['Id','CreationDate', 'OwnerUserId', 'PostText', 'CodeCount', 'Score']],
    right=user_locations,
    on='OwnerUserId',
    how='inner'
)

# Calculate sentiment for each post
location_df['SentimentScore'] = location_df['PostText'].apply(get_sentiment_score)
location_df['Sentiment'] = location_df['SentimentScore'].apply(classify_sentiment)
```

Quick look at the location dataset

```{python}
location_df
```

### Extract the coordinates of the user's location

Based on the locations in the datset, we call the `geopy` function to extract the longitude and latitude of the location.

```{python}
from geopy.geocoders import Nominatim
# Function to get latitude and longitude for a location
def get_lat_long(location):
    geolocator = Nominatim(user_agent="GeoApi") #Initialize the model
    try:
        location = geolocator.geocode(location)
        print(location)
        if location:
            return location.latitude, location.longitude
        else:
            return None, None
    except Exception as e:
        print(f"Error geocoding location: {e}")
        return None, None
# Apply geocoding to get coordinates (this may take time)
location_df['Coordinates'] = location_df['Location'].apply(
    lambda x: get_lat_long(x) if pd.notnull(x) else (None, None)
)
location_df['Latitude'] = location_df['Coordinates'].apply(lambda x: x[0] if x is not None else None)
location_df['Longitude'] = location_df['Coordinates'].apply(lambda x: x[1] if x is not None else None)

# Filter out rows with no coordinates
geo_df = location_df.dropna(subset=['Latitude', 'Longitude'])
```

### Maps of ChatGPT posts user

We create a map of users' locations based on the extracted coordinates and color the pins by sentiments

```{python}
# Create a basic map centered at the mean of the coordinates
center_lat = geo_df['Latitude'].mean()
center_lng = geo_df['Longitude'].mean()
map_base = folium.Map(location=[center_lat, center_lng], zoom_start=3)

# Add markers with clustering
marker_cluster = MarkerCluster().add_to(map_base)

# Define color function based on sentiment
def get_color(sentiment):
    if sentiment == 'Positive':
        return 'green'
    elif sentiment == 'Negative':
        return 'red'
    else:
        return 'blue'

# Add each point to the map
for idx, row in geo_df.iterrows():
    popup_text = f"""
    <strong>Location:</strong> {row['Location']}<br>
    <strong>Sentiment:</strong> {row['Sentiment']}<br>
    <strong>Score:</strong> {row['Score']}<br>
    <strong>CodeCount:</strong> {row['CodeCount']}
    """
    
    folium.Marker(
        location=[row['Latitude'], row['Longitude']],
        popup=folium.Popup(popup_text, max_width=300),
        icon=folium.Icon(color=get_color(row['Sentiment']))
    ).add_to(marker_cluster)

# Save the map
map_base.save('chatgpt_post_locations.html')
display(map_base)
```

This map shows that the users of this particular thread come from every continent in the world. However, the continent with the highest concentration is Europe. This is followed by Asia with 52 users and North America with 47 users. A closer look into each continent shows that, most of the users post positive discussion about ChatGPT and there are only a small number of negative posts in each continent. 

## 9. Advanced Insights

In this section, we delve deeper into the dataset to uncover advanced insights by leveraging thematic analysis and geospatial visualization. Using AI-powered tools, we extract thematic categories from posts and comments to identify key discussion topics, such as ethical concerns, technical implementations, and privacy issues. Additionally, we analyze the geographical distribution of posts to understand how discussions about ChatGPT vary across different regions. This section aims to provide a comprehensive understanding of the broader context and themes surrounding ChatGPT discussions, offering valuable perspectives on the global and thematic dimensions of the dataset.

### Set up the Ollama API call function

```{python}
# Install Ollama
curl -fsSL https://ollama.com/download/ollama-darwin-amd64 -o ollama
chmod +x ollama
sudo mv ollama /usr/local/bin/

# Start Ollama service
ollama serve

# In a new terminal, pull the DeepSeek model
ollama pull deepseek-r1:latest

# Verify installation
ollama list
```

```{python}
def query_ollama(prompt, model="deepseek-r1:latest"):
    url = "http://localhost:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
    }
    response = requests.post(url, json=payload)
    result = ""
    for line in response.text.splitlines():
        data = json.loads(line)
        if "response" in data:
            result += data["response"]
    return result.strip()
```

### Prepare the prompt for the model

```{python}
def get_theme(text):
    prompt = f"Summarize the following text in about 7-8 words and assign it to a thematic category (e.g., Ethical concern, Technical Implementation, Privacy Problem, ...). Give your answer in the format: Summary: ... Category: ... . There should be no redundant information and ensure that all text should be summarised. Here is the text: {text}"
    response = query_ollama(prompt)

    return response
```

### Extract the theme of each post

*This cell could take up to 2 hours to run depending on the computer's hardware*

```{python}
merged_df["TotalText"] = merged_df["CleanBody"] + " " + merged_df["CleanComment"]
merged_df["Theme"] = merged_df["TotalText"].apply(get_theme)
```

```{python}
merged_df["Theme"][1]
```

### Function to clean the model's response

We create a function to remove redundant information in the model's reponse and then extract the summary and category section.

```{python}
def extract_theme_components(theme_text):
    """
    Extract the summary and category from the themed text.
    
    Parameters:
        theme_text (str): The theme text to parse
        
    Returns:
        tuple: (summary, category)
    """
    if pd.isna(theme_text) or not isinstance(theme_text, str):
        return ("Unknown", "Uncategorized")
    
    # Remove <think>...</think> parts
    theme_text = re.sub(r'<think>.*?</think>', '', theme_text, flags=re.DOTALL).strip()
    
        
    # Try to extract using the expected format
    try:
        # Look for the pattern "Summary: ... Category: ..."
        if "Summary:" in theme_text and "Category:" in theme_text:
            parts = theme_text.split("Category:")
            summary = parts[0].replace("Summary:", "").strip()
            category = parts[1].strip()
        # Sometimes the format might be different
        elif ":" in theme_text:
            # Try to find the last colon which might separate summary from category
            parts = theme_text.rsplit(":", 1)
            summary = parts[0].strip()
            category = parts[1].strip()
        else:
            # Default fallback
            summary = theme_text
            category = "General"
            
        # Clean and standardize categories
        category = category.strip().title()
        if not category:
            category = "General"
            
        return (summary, category)
    except Exception as e:
        print(f"Error parsing theme: {e}")
        return (theme_text, "Parsing Error")
```

```{python}
# Apply the extraction function to the Theme column
merged_df[['Summary', 'Category']] = merged_df['Theme'].apply(
    lambda x: pd.Series(extract_theme_components(x))
)

merged_df['Category'] = merged_df['Category'].apply(clean_text)
# Look at the distribution of categories
category_counts = merged_df['Category'].value_counts()
category_counts
```

We find a lot of interesting category from the model's response. The pattern is that most of the discussions is related to technical implementations which reflects the nature of Stack Exchange, a platform designated for developers. However, a noticeable number of discussions concentrates on ethical concern of ChatGPT, which is still a highly debatable issue till the current day.

```{python}
merged_df['Summary'][0]
```

```{python}
group = merged_df.groupby("Category")['Summary'].count().sort_values(ascending=False)
print(group)
```

### Sunburst chart for the categories

```{python}
import plotly.express as px

# Prepare data for sunburst
sunburst_data = merged_df[['Category', 'Summary']].value_counts().reset_index()
sunburst_data.columns = ['Category', 'Summary', 'Count']

# Create sunburst chart
fig = px.sunburst(
    sunburst_data,
    path=['Category', 'Summary'],
    values='Count',
    title='Category and Summary Hierarchy',
    width=1800,  # Set the width of the chart
    height=1500   # Set the height of the chart
)
# Adjust label orientation for better readability
fig.update_traces(insidetextorientation='horizontal')  # Options: 'radial', 'horizontal', 'auto'

fig.show()
```

Looking closer at the sumamries in each category, we can see that LLM could perform really well in summarizing a long-context input in a short and concise sentence. Although some of the instances do not strictly follow the rules set in the query, we still get very informative results. One of which is the discussion raised on ethical concern. Users express varying opinions about data privacy, OpenAI's profit maximization strategy and AI alignments with human values which are all worth considering further. 

## 10. Discussion



## Overall Observations from the Analysis

Looking at the graphs and analysis results, several key population-level observations can be made:

1. **Temporal Evolution**: ChatGPT discussions showed minimal activity from 2015-2018, followed by gradual growth in 2018-2019, and a dramatic spike in 2023 coinciding with GPT-3's release. The sharp decline in 2024 suggests a potential shift in discussion focus or platform usage.

2. **Content Characteristics**: Posts tend to be concise (mostly 50-200 words) and technically oriented, with a significant majority containing code blocks, reflecting Stack Exchange's developer-centric nature.

3. **Sentiment Distribution**: There's a strong positive sentiment bias in posts (402 positive vs 62 negative), while comments exhibit more neutrality (326 neutral vs 145 positive), suggesting initial enthusiasm followed by more measured discussion.

4. **Global Distribution**: While users come from all continents, Europe shows the highest concentration, followed by Asia and North America, with predominantly positive sentiment across regions.

5. **Thematic Patterns**: Technical implementation discussions dominate, followed by ethical concerns, reflecting both practical and philosophical considerations about ChatGPT technology.

## 11. Notes on privacy and ethics

### Reflection on Data Privacy and Ethics Issues  

During the data analysis process, several potential data privacy and ethics concerns arise that warrant careful consideration:  

1. **User Anonymity and Privacy**:  
   The dataset includes user-generated content, such as posts, comments, and location data. Even though the data may appear anonymized, there is a risk of re-identification, especially when combining multiple data points (e.g., location and user activity). Ensuring that no personally identifiable information (PII) is exposed is critical to maintaining user privacy.  

2. **Ethical Use of Location Data**:  
   The analysis of user-provided location data introduces ethical concerns. Users may not have explicitly consented to their location being used for geospatial analysis. Additionally, inaccuracies in geocoding could lead to misrepresentation of user locations, potentially causing harm or misinterpretation of results.  

3. **Bias in Data Representation**:  
   The dataset may inherently reflect biases, such as overrepresentation of certain regions, demographics, or viewpoints. This could lead to skewed insights that fail to represent the global or diverse perspectives on ChatGPT. Addressing these biases is essential to ensure fair and balanced analysis.  

4. **Sentiment Misclassification**:  
   Sentiment analysis relies on algorithms that may misinterpret the tone or context of user-generated content. This could lead to incorrect conclusions about user opinions, potentially misrepresenting the sentiment of discussions.  

5. **Ethical Implications of Thematic Analysis**:  
   Thematic analysis involves categorizing user discussions into topics, which may inadvertently oversimplify or misrepresent the complexity of user concerns. Care must be taken to ensure that the themes accurately reflect the content without introducing researcher bias.  

6. **Transparency and Accountability**:  
   It is important to maintain transparency about the methods and tools used in the analysis. Users whose data is being analyzed should ideally be informed about how their data is being used and for what purpose.  

To address these concerns, it is crucial to implement robust data anonymization techniques, ensure compliance with ethical guidelines, and critically evaluate the limitations of the analysis methods. Additionally, researchers should strive to minimize bias, respect user privacy, and maintain accountability throughout the data analysis process.

## Conclusion

The analysis reveals significant trends and patterns in discussions about ChatGPT, including the prevalence of technical topics, sentiment distribution, and regional variations in user engagement. Sentiment analysis highlights a predominantly positive outlook in posts, while comments tend to be more neutral. Thematic analysis uncovers key discussion topics, such as ethical concerns, technical implementations, and privacy issues. Geospatial visualization provides insights into the global distribution of discussions. Throughout the project, ethical considerations were prioritized to ensure responsible data handling. Overall, this study offers a comprehensive understanding of the discourse surrounding ChatGPT, contributing to the broader conversation about AI technologies and their societal impact.


